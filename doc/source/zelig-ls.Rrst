.. _zls:

zelig-ls
~~~~~~

Least Squares Regression for Continuous Dependent Variables

Use least squares regression analysis to estimate the best linear
predictor for the specified dependent variables.

Syntax
+++++

With reference classes:

.. {r, eval = FALSE}
z5 <- zls$new()
z5$zelig(Y ~ X1 + X ~ X, weights = w, data = mydata)
z5$setx()
z5$sim()
.. ..

With the Zelig 4 compatibility wrappers:

.. {r, eval = FALSE}
z.out <- zelig(Y ~ X1 + X2, model = "ls", weights = w, data = mydata)
x.out <- setx(z.out)
s.out <- sim(z.out, x = x.out)
.. ..

Examples
+++++

.. {r, eval = TRUE, echo = FALSE}
rm(list=ls(pattern="\\.out"))	
suppressWarnings(suppressMessages(library(Zelig)))
set.seed(1234)
.. .. 

Basic Example with First Differences
!!!!!

Attach sample data:

.. {r, eval = TRUE}
data(macro)
.. ..

Estimate model:

.. {r, eval = TRUE}
z.out1 <- zelig(unem ~ gdp + capmob + trade, model = "ls", data = macro)
.. ..

Summarize regression coefficients:

.. {r, eval = TRUE}
summary(z.out1)
.. ..

Set explanatory variables to their default (mean/mode) values, with
high (80th percentile) and low (20th percentile) values for the trade
variable:

.. {r, eval = TRUE}
x.high <- setx(z.out1, trade = quantile(macro$trade, 0.8))
x.low <- setx(z.out1, trade = quantile(macro$trade, 0.2))
.. ..

Generate first differences for the effect of high versus low trade on GDP:

.. {r, eval = TRUE}
s.out1 <- sim(z.out1, x = x.high, x1 = x.low)
.. ..

.. {r, eval = TRUE}
summary(s.out1)
.. ..

.. {r Zelig-ls, dev=c("png", "pdf"), eval = TRUE, fig.cap = "Graphs of Quantities of Interest for Linear Regression"}
plot(s.out1)
.. ..

Using Dummy Variables
!!!!!

Estimate a model with fixed effects for each country (see for help
with dummy variables). Note that you do not need to create dummy
variables, as the program will automatically parse the unique values
in the selected variable into discrete levels.

.. {r, eval = TRUE}
z.out2 <- zelig(unem ~ gdp + trade + capmob + as.factor(country), model = "ls", data = macro)
.. ..

Set values for the explanatory variables, using the default mean/mode
values, with country set to the United States and Japan,
respectively:

.. {r, eval = TRUE}
x.US <- setx(z.out2, country = "United States")
x.Japan <- setx(z.out2, country = "Japan")
.. ..
   
Simulate quantities of interest:

.. {r, eval = TRUE}
s.out2 <- sim(z.out2, x = x.US, x1 = x.Japan)
.. ..

.. {r , dev=c("png", "pdf"), eval = TRUE, fig.cap = "Graphs of Quantities of Interest for Linear Regression"}
plot(s.out2)
.. ..

Model
+++++

-  The *stochastic component* is described by a density with mean
   :math:`\mu_i` and the common variance :math:`\sigma^2`

   .. math:: Y_i \; \sim \; f(y_i \mid \mu_i, \sigma^2).

-  The *systematic component* models the conditional mean as

   .. math:: \mu_i =  x_i \beta

   where :math:`x_i` is the vector of covariates, and :math:`\beta` is
   the vector of coefficients.

   The least squares estimator is the best linear predictor of a
   dependent variable given :math:`x_i`, and minimizes the sum of
   squared residuals, :math:`\sum_{i=1}^n (Y_i-x_i \beta)^2`.

Quantities of Interest
+++++

-  The expected value (qi$ev) is the mean of simulations from the
   stochastic component,

   .. math:: E(Y) = x_i \beta,

   given a draw of :math:`\beta` from its sampling distribution.

-  In conditional prediction models, the average expected treatment
   effect (att.ev) for the treatment group is

   .. math::

      \frac{1}{\sum_{i=1}^n t_i}\sum_{i:t_i=1}^n \left\{ Y_i(t_i=1) -
            E[Y_i(t_i=0)] \right\},

   where :math:`t_i` is a binary explanatory variable defining the
   treatment (:math:`t_i=1`) and control (:math:`t_i=0`) groups.
   Variation in the simulations are due to uncertainty in simulating
   :math:`E[Y_i(t_i=0)]`, the counterfactual expected value of
   :math:`Y_i` for observations in the treatment group, under the
   assumption that everything stays the same except that the treatment
   indicator is switched to :math:`t_i=0`.

Output Values
+++++

The output of each Zelig command contains useful information which you
may view. For example, if you run
``z.out <- zelig(y ~ x, model = ls, data)``, then you may examine the
available information in ``z.out`` by using ``names(z.out)``, see the
coefficients by using z.out$coefficients, and a default summary of
information through ``summary(z.out)``. Other elements available through
the $ operator are listed below.

-  From the zelig() output object z.out, you may extract:

   -  coefficients: parameter estimates for the explanatory variables.

   -  residuals: the working residuals in the final iteration of the
      IWLS fit.

   -  fitted.values: fitted values.

   -  df.residual: the residual degrees of freedom.

   -  zelig.data: the input data frame if save.data = TRUE.

-  From summary(z.out), you may extract:

   -  coefficients: the parameter estimates with their associated
      standard errors, :math:`p`-values, and :math:`t`-statistics.

      .. math:: \hat{\beta} \; = \; \left(\sum_{i=1}^n x_i' x_i\right)^{-1} \sum x_i y_i

   -  sigma: the square root of the estimate variance of the random
      error :math:`e`:

      .. math:: \hat{\sigma} \; = \; \frac{\sum (Y_i-x_i\hat{\beta})^2}{n-k}

   -  r.squared: the fraction of the variance explained by the model.

      .. math::

         R^2 \; = \; 1 - \frac{\sum (Y_i-x_i\hat{\beta})^2}{\sum (y_i -
                  \bar{y})^2}

   -  adj.r.squared: the above :math:`R^2` statistic, penalizing for an
      increased number of explanatory variables.

   -  cov.unscaled: a :math:`k \times k` matrix of unscaled covariances.

See also
+++++

The least squares regression is part of the stats package by William N.
Venables and Brian D. Ripley .In addition, advanced users may wish to
refer to ``help(lm)`` and ``help(lm.fit)``.

.. {r, eval = TRUE, echo=FALSE, results = "asis"} 
z5 <- zls$new()
z5$references()
.. ..
