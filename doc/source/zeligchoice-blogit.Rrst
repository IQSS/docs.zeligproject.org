.. _zcblogit:

zeligchoice-blogit
~~~~~~

Bivariate Logistic Regression for Two Dichotomous Dependent Variables

Use the bivariate logistic regression model if you have two binary
dependent variables :math:`(Y_1, Y_2)`, and wish to model them jointly
as a function of some explanatory variables. Each pair of dependent
variables :math:`(Y_{i1}, Y_{i2})` has four potential outcomes,
:math:`(Y_{i1}=1,
Y_{i2}=1)`, :math:`(Y_{i1}=1, Y_{i2}=0)`, :math:`(Y_{i1}=0, Y_{i2}=1)`,
and :math:`(Y_{i1}=0, Y_{i2}=0)`. The joint probability for each of
these four outcomes is modeled with three systematic components: the
marginal Pr\ :math:`(Y_{i1} = 1)` and Pr\ :math:`(Y_{i2} = 1)`, and the
odds ratio :math:`\psi`, which describes the dependence of one marginal
on the other. Each of these systematic components may be modeled as
functions of (possibly different) sets of explanatory variables.

Syntax
+++++

With reference classes:

.. {r, eval = FALSE}
z5 <- zblogit$new()
z5$zelig(cbind(Y1, Y2) ~ X1 + X2 + X3, data = mydata)
z5$setx()
z5$sim()
.. ..

With the Zelig 4 compatibility wrappers:

.. {r, eval = FALSE}
z.out <- zelig(cbind(Y1, Y2) ~ X1 + X2 + X3, 
               model = "blogit", data = mydata)
x.out <- setx(z.out)
s.out <- sim(z.out, x = x.out, x1 = NULL)
.. ..

Input Values
+++++

In every bivariate logit specification, there are three equations which
correspond to each dependent variable (:math:`Y_1`, :math:`Y_2`), and
:math:`\psi`, the odds ratio. You should provide a list of formulas for
each equation or, you may use cbind() if the right hand side is the same
for both equations

.. {r, eval = FALSE}
formulae <- list(cbind(Y1,Y2)   X1 + X2)
.. ..

which means that all the explanatory variables in equations 1 and 2
(corresponding to :math:`Y_1` and :math:`Y_2`) are included, but only an
intercept is estimated (all explanatory variables are omitted) for
equation 3 (:math:`\psi`).

You may use the function tag() to constrain variables across equations:

.. {r, eval = FALSE}
formulae <- list(mu1 = y1   x1 + tag(x3, "x3"), mu2 = y2 ~ x2 + tag(x3, "x3"))
.. ..

where `tag()` is a special function that constrains variables to have the
same effect across equations. Thus, the coefficient for x3 in equation
mu1 is constrained to be equal to the coefficient for x3 in equation
mu2.

Examples
+++++

.. {r, eval = TRUE, echo = FALSE}
rm(list=ls(pattern="\\.out"))
suppressWarnings(suppressMessages(library(Zelig)))	
suppressWarnings(suppressMessages(library(ZeligChoice)))
set.seed(1234)
.. ..

Basic Example 
!!!!!

Load the data and estimate the model:

.. {r, eval = TRUE}
data(sanction)
.. ..

.. {r, eval = TRUE}
z.out1 <- zelig(cbind(import, export) ~ coop + cost + target,
                model = "blogit", data = sanction)
summary(z.out1)
.. ..

By default, zelig() estimates two effect parameters for each
explanatory variable in addition to the odds ratio parameter; this
formulation is parametrically independent (estimating unconstrained
effects for each explanatory variable), but stochastically dependent
because the models share an odds ratio. Generate baseline values for
the explanatory variables (with cost set to 1, net gain to sender) and alternative values (with cost set to 4, major loss to sender):

.. {r, eval = TRUE}
x.low <- setx(z.out1, cost = 1)
x.high <- setx(z.out1, cost = 4)
.. ..

Simulate fitted values and first differences:

.. {r, eval = TRUE}
s.out1 <- sim(z.out1, x = x.low, x1 = x.high)
.. ..

.. {r, eval = TRUE}
summary(s.out1)
.. ..

.. {r, eval = TRUE, Zelig-blogit-1, dev=c("png", "pdf"), eval = TRUE, fig.cap = "Graphs of Quantities of Interest for Zelig-blogit-1"}
plot(s.out1)
.. ..
   
Joint Estimation of a Model with Different Sets of Explanatory Variables
!!!!!

Using sample data ``sanction``, estimate the statistical model, with
import a function of coop in the first equation and export a function of cost and target in the second equation:

.. {r, eval = TRUE}
z.out2 <- zelig(cbind(import, export) ~ coop, model = "blogit", data = sanction)
summary(z.out2)
.. ..

Set the explanatory variables to their means:

.. {r, eval = TRUE}
x.out2 <- setx(z.out2)
.. ..

Simulate draws from the posterior distribution:

.. {r, eval = TRUE}
s.out2 <- sim(z.out2, x = x.out2)
summary(s.out2)
.. ..

.. {r, eval = TRUE, Zelig-blogit-2, dev=c("png", "pdf"), eval = TRUE, fig.cap = "Graphs of Quantities of Interest for Zelig-blogit-2"}
plot(s.out2)
.. ..

Joint Estimation of a Parametrically and Stochastically Dependent Model
!!!!!

Using the sample data ``sanction`` The bivariate model is
parametrically dependent if :math:`Y_1` and :math:`Y_2` share some or
all explanatory variables, *and* the effects of the shared explanatory variables are jointly estimated. For example,

.. {r, eval = FALSE}
z.out3 <- zelig(list(import ~ tag(coop, "coop") + tag(cost, "cost") + tag(target, "target"),
                     export ~ tag(coop, "coop") + tag(cost, "cost") + tag(target, "target")),
                model = "blogit", data = sanction)
summary(z.out3)
.. .. 

Note that this model only returns one parameter estimate for each of coop, cost, and target. Contrast this to Example [basic.bl] which returns two parameter estimates for each of the explanatorvvariables. Set values for the explanatory variables:

.. {r, eval = FALSE}
x.out3 <- setx(z.out3, cost = 1:4)
.. ..

Draw simulated expected values:

.. {r, eval = FALSE}
s.out3 <- sim(z.out3, x = x.out3)
summary(s.out3)
.. ..

Model
!!!!!

For each observation, define two binary dependent variables, :math:`Y_1`
and :math:`Y_2`, each of which take the value of either 0 or 1 (in the
following, we suppress the observation index). We model the joint
outcome :math:`(Y_1`, :math:`Y_2)` using a marginal probability for each
dependent variable, and the odds ratio, which parameterizes the
relationship between the two dependent variables. Define :math:`Y_{rs}`
such that it is equal to 1 when :math:`Y_1=r` and :math:`Y_2=s` and is 0
otherwise, where :math:`r` and :math:`s` take a value of either 0 or 1.
Then, the model is defined as follows,

-  The *stochastic component* is

   .. math::

      \begin{aligned}
        Y_{11} &\sim& \textrm{Bernoulli}(y_{11} \mid \pi_{11}) \\
        Y_{10} &\sim& \textrm{Bernoulli}(y_{10} \mid \pi_{10}) \\
        Y_{01} &\sim& \textrm{Bernoulli}(y_{01} \mid \pi_{01})\end{aligned}

   where :math:`\pi_{rs}=\Pr(Y_1=r, Y_2=s)` is the joint probability,
   and :math:`\pi_{00}=1-\pi_{11}-\pi_{10}-\pi_{01}`.

-  The *systematic components* model the marginal probabilities,
   :math:`\pi_j=\Pr(Y_j=1)`, as well as the odds ratio. The odds ratio
   is defined as :math:`\psi = \pi_{00} \pi_{01}/\pi_{10}\pi_{11}` and
   describes the relationship between the two outcomes. Thus, for each
   observation we have

   .. math::

      \begin{aligned}
      \pi_j & = & \frac{1}{1 + \exp(-x_j \beta_j)} \quad \textrm{ for} \quad
      j=1,2, \\
      \psi &= & \exp(x_3 \beta_3).\end{aligned}

Quantities of Interest
!!!!!

-  The expected values (qi$ev) for the bivariate logit model are the
   predicted joint probabilities. Simulations of :math:`\beta_1`,
   :math:`\beta_2`, and :math:`\beta_3` (drawn from their sampling
   distributions) are substituted into the systematic components
   :math:`(\pi_1, \pi_2, \psi)` to find simulations of the predicted joint probabilities:

   .. math::

      \begin{aligned}
      \pi_{11} & = & \left\{ \begin{array}{ll}
                       \frac{1}{2}(\psi - 1)^{-1} - {a - \sqrt{a^2 + b}} &
                       \textrm{for} \; \psi \ne 1 \\
                       \pi_1 \pi_2 & \textrm{for} \; \psi = 1 
                       \end{array} \right., \\
      \pi_{10} &=& \pi_1 - \pi_{11}, \\
      \pi_{01} &=& \pi_2 - \pi_{11}, \\
      \pi_{00} &=& 1 - \pi_{10} - \pi_{01} - \pi_{11},\end{aligned}

   where :math:`a = 1 + (\pi_1 + \pi_2)(\psi - 1)`,
   :math:`b = -4 \psi(\psi - 1)
   \pi_1 \pi_2`, and the joint probabilities for each observation must
   sum to one. For :math:`n` simulations, the expected values form an
   :math:`n \times 4` matrix for each observation in x.

-  The predicted values (qi$pr) are draws from the multinomial
   distribution given the expected joint probabilities.

-  The first differences (qi$fd) for each of the predicted joint
   probabilities are given by

   .. math::

      \textrm{FD}_{rs}
        = \Pr(Y_1=r, Y_2=s \mid x_1)-\Pr(Y_1=r, Y_2=s \mid x).

-  The risk ratio (qi$rr) for each of the predicted joint probabilities
   are given by

   .. math:: \textrm{RR}_{rs} = \frac{\Pr(Y_1=r, Y_2=s \mid x_1)}{\Pr(Y_1=r, Y_2=s \mid x)}

-  In conditional prediction models, the average expected treatment
   effect (att.ev) for the treatment group is

   .. math::

      \frac{1}{\sum_{i=1}^n t_i}\sum_{i:t_i=1}^n \left\{ Y_{ij}(t_i=1) -
            E[Y_{ij}(t_i=0)] \right\} \textrm{ for } j = 1,2,

   where :math:`t_i` is a binary explanatory variable defining the
   treatment (:math:`t_i=1`) and control (:math:`t_i=0`) groups.
   Variation in the simulations are due to uncertainty in simulating
   :math:`E[Y_{ij}(t_i=0)]`, the counterfactual expected value of
   :math:`Y_{ij}` for observations in the treatment group, under the
   assumption that everything stays the same except that the treatment
   indicator is switched to :math:`t_i=0`.

-  In conditional prediction models, the average predicted treatment
   effect (att.pr) for the treatment group is

   .. math::

      \frac{1}{\sum_{i=1}^n t_i}\sum_{i:t_i=1}^n \left\{ Y_{ij}(t_i=1) -
            \widehat{Y_{ij}(t_i=0)} \right\} \textrm{ for } j = 1,2,

   where :math:`t_i` is a binary explanatory variable defining the
   treatment (:math:`t_i=1`) and control (:math:`t_i=0`) groups.
   Variation in the simulations are due to uncertainty in simulating
   :math:`\widehat{Y_{ij}(t_i=0)}`, the counterfactual predicted value
   of :math:`Y_{ij}` for observations in the treatment group, under the
   assumption that everything stays the same except that the treatment
   indicator is switched to :math:`t_i=0`.

Output Values
!!!!!

The output of each Zelig command contains useful information which you
may view. For example, if you run
``z.out <- zelig(y ~ x, model = "blogit", data)``, then you may examine
the available information in ``z.out`` by using ``names(z.out)``, see
the coefficients by using z.out$coefficients, and obtain a default
summary of information through summary(z.out). Other elements available
through the $ operator are listed below.

-  From the zelig() output object z.out, you may extract:

   -  coefficients: the named vector of coefficients.

   -  fitted.values: an :math:`n \times 4` matrix of the in-sample
      fitted values.

   -  predictors: an :math:`n \times 3` matrix of the linear predictors
      :math:`x_j \beta_j`.

   -  residuals: an :math:`n \times 3` matrix of the residuals.

   -  df.residual: the residual degrees of freedom.

   -  df.total: the total degrees of freedom.

   -  rss: the residual sum of squares.

   -  y: an :math:`n \times 2` matrix of the dependent variables.

   -  zelig.data: the input data frame if save.data = TRUE.

-  From summary(z.out), you may extract:

   -  coef3: a table of the coefficients with their associated standard
      errors and :math:`t`-statistics.

   -  cov.unscaled: the variance-covariance matrix.

   -  pearson.resid: an :math:`n \times 3` matrix of the Pearson
      residuals.


See also
!!!!!

The bivariate logit function is part of the VGAM package by Thomas Yee .
In addition, advanced users may wish to refer to ``help(vglm)`` in the
VGAM library.

.. {r, eval = TRUE, echo=FALSE, results = "asis"} 
z5 <- zblogit$new()
z5$references()
.. ..
